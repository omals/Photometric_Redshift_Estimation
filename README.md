# On the Performance of Machine Learning Models and Hybrid Ensembles with Neural Embeddings for Photometric Redshift Estimation

**Leveraging Machine Learning and Ensemble Techniques for Reliable Photometric Redshift Estimation**

This repository contains the complete implementation of the research work:

> **Omal S., Dr. Madhu S. Nair**

The study systematically evaluates classical machine learning models, deep neural networks, and hybrid ensemble architectures for large-scale photometric redshift (photo-z) estimation using SDSS data .

---

# ðŸ“Œ Project Overview

Photometric redshift (photo-z) estimation enables scalable redshift prediction using multi-band photometric observations, avoiding expensive spectroscopic measurements.

This project:

* Uses **36 optimized photometric + morphological features**
* Evaluates classical ML, ensemble, and deep learning models
* Proposes **hybrid neural-ensemble architectures**
* Benchmarks performance across two redshift regimes

---

# ðŸ“Š Dataset

## Source

* Sloan Digital Sky Survey (SDSS DR18)

## Dataset Statistics

* Original dataset: ~4.25M objects
* Cleaned dataset: ~3.7M objects 
* Train / Validation / Test split: **70 / 15 / 15**

## Redshift Ranges

* **D1**: 0 â‰¤ z â‰¤ 2 (Low redshift)
* **D2**: 0 â‰¤ z â‰¤ 8 (Full range)

## Selected Features (36)

Includes:

* ugriz magnitudes
* Petrosian radii & fluxes
* PSF magnitudes
* Axis ratios (expAB)
* Model magnitudes
* Derived color indices: (uâˆ’g, gâˆ’r, râˆ’i, iâˆ’z)

Feature selection performed using Pearson correlation with redshift .

---

# ðŸ§  Implemented Models

## 1ï¸âƒ£ Classical Regression

* Linear Regression
* Ridge
* Lasso
* Elastic Net
* KNN
* SVR
* Gaussian Process Regression

## 2ï¸âƒ£ Tree-Based Ensembles

* Decision Tree
* Random Forest
* XGBoost

## 3ï¸âƒ£ Deep Learning Models

### Neural Network (NN)

Architecture:

```
128 â†’ 64 â†’ 32 â†’ 1
```

* ReLU
* LayerNorm
* Dropout (0.2)
* Adam (lr=0.001)
* MSE Loss 

### Fully Connected Network (FCN)

```
100 â†’ 65 â†’ 35 â†’ 1
```

---

## 4ï¸âƒ£ Hybrid Ensemble Models (Best Performing)

* NN + Random Forest
* NN + XGBoost
* FCN + Random Forest
* FCN + XGBoost

Hybrid models combine:

* Neural embeddings (representation learning)
* Ensemble regression (variance reduction & stability)

Performance improvements confirmed experimentally .

---

# ðŸ† Key Results

## D1 (0 â‰¤ z â‰¤ 2)

| Model                  | RMSE       | RÂ²         |
| ---------------------- | ---------- | ---------- |
| Random Forest          | 0.1615     | 0.8603     |
| XGBoost                | 0.1539     | 0.8734     |
| Neural Network         | 0.1592     | 0.8645     |
| **NN + Random Forest** | **0.1521** | **0.8763** |

## D2 (0 â‰¤ z â‰¤ 8)

| Model                  | RMSE       | RÂ²         |
| ---------------------- | ---------- | ---------- |
| Random Forest          | 0.3747     | 0.7089     |
| XGBoost                | 0.3591     | 0.7324     |
| Neural Network         | 0.3596     | 0.7315     |
| **NN + Random Forest** | **0.3566** | **0.7361** |

Hybrid approaches consistently outperform standalone models .

---

# ðŸ— Repository Structure

```
photoz-hybrid-ensemble/
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ values content loaded
â”‚   â”œâ”€â”€ correlation.py
â”‚   â”œâ”€â”€ distribution.py
â”‚   â””â”€â”€ preprocessing.ipynb
â”‚
â”œâ”€â”€ Model/
â”‚   â”œâ”€â”€ FCN_xgboost.py
â”‚   â”œâ”€â”€ NN_xgboost.py
â”‚   â”œâ”€â”€ decision_tree.py
â”‚   â”œâ”€â”€ gaussian_process_regression.ipynb
â”‚   â”œâ”€â”€ knn.py
â”‚   â”œâ”€â”€ linear_models.ipynb
â”‚   â”œâ”€â”€ randomforest.py
â”‚   â”œâ”€â”€ svr.py
â”‚   â””â”€â”€ xgboost.py
â”‚
â”œâ”€â”€ Output/
â”‚   â”‚
â”‚   â”œâ”€â”€ Images/
â”‚   â”‚   â”œâ”€â”€ knn_d1.jpeg
â”‚   â”‚   â”œâ”€â”€ knn_d2.jpeg
â”‚   â”‚   â”œâ”€â”€ randomforest_d1.jpeg
â”‚   â”‚   â”œâ”€â”€ randomforest_d2.jpeg
â”‚   â”‚   â”œâ”€â”€ redshift_dist.jpeg
â”‚   â”‚   â”œâ”€â”€ svr_d1.jpeg
â”‚   â”‚   â”œâ”€â”€ svr_d2.jpeg
â”‚   â”‚   â”œâ”€â”€ xgboost_d1.jpeg
â”‚   â”‚   â””â”€â”€ xgboost_d2.jpeg
â”‚   â”‚
â”‚   â””â”€â”€ values/
â”‚       â”œâ”€â”€ Hybrid_ensemble model results.txt
â”‚       â”œâ”€â”€ knn_d1.txt
â”‚       â”œâ”€â”€ knn_d2.txt
â”‚       â”œâ”€â”€ randomforest_d1.txt
â”‚       â”œâ”€â”€ randomforest_d2.txt
â”‚       â”œâ”€â”€ svr_d1.txt
â”‚       â”œâ”€â”€ svr_d2.txt
â”‚       â”œâ”€â”€ xgboostd1.txt
â”‚       â””â”€â”€ xgboostd2.txt
â”‚
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

# âš™ï¸ Installation

```bash
git clone https://github.com/your-username/photoz-hybrid-ensemble.git
cd photoz-hybrid-ensemble
pip install -r requirements.txt
```

## Requirements

* Python 3.9+
* NumPy
* Pandas
* Scikit-learn
* XGBoost
* PyTorch
* Matplotlib

---

# ðŸš€ Usage

## Train Neural Network

```bash
python train.py 
```

## Train Hybrid Model

```bash
python train.py 
```

## 5-Fold Cross Validation

```bash
python cross_validation.py 
```

---

# ðŸ–¥ Computational Setup

Experiments were conducted on:

* Dual AMD EPYC (64 cores)
* Dual NVIDIA A100 (80GB)
* CUDA 12.9 

---

# ðŸ”¬ Scientific Contributions

* Comprehensive comparison of regression techniques
* Demonstrates strong non-linearity in photo-z problem
* Shows superiority of hybrid neural + ensemble models
* Scalable framework for large sky surveys

---

# ðŸŒ  Applicability to Future Surveys

This framework is suitable for next-generation missions:

* Vera C. Rubin Observatory (LSST)
* Euclid
* Nancy Grace Roman Space Telescope

These missions require accurate, scalable photometric redshift estimation .

---

# ðŸ“š Related Literature

* Review of photo-z techniques 
* Early SDSS photo-z implementation 

---

# ðŸ”® Future Work

* Uncertainty estimation (photo-z PDFs)
* Outlier detection
* Domain adaptation
* Explainability (SHAP analysis on embeddings)
* Probabilistic calibration

---

# ðŸ‘¨â€ðŸ’» Author

**Omals**
Department of Computer Science
CUSAT

Guided by **Dr. Madhu S. Nair**

---

# ðŸ“Œ Summary

This repository demonstrates that:

> **Hybrid neural embedding + ensemble regression provides a robust, scalable, and high-accuracy solution for large-scale photometric redshift estimation.**

---
